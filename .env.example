# Get your Open AI API Key by following these instructions -
# https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# You only need this environment variable set if you are using GPT (and not Ollama or Gemini)
OPENAI_API_KEY=

# You only need this environment variable set if you are using Gemini (and not Ollama or chatgpt)
GOOGLE_API_KEY=

# For the Supabase version (sample_supabase_agent.py), set your Supabase URL and Service Key.
# Get your SUPABASE_URL from the API section of your Supabase project settings -
# https://supabase.com/dashboard/project/<your project ID>/settings/api
SUPABASE_URL=

# Get your SUPABASE_SERVICE_KEY from the API section of your Supabase project settings -
# https://supabase.com/dashboard/project/<your project ID>/settings/api
# On this page it is called the service_role secret.
SUPABASE_SERVICE_KEY=

# The LLM you want to use from OpenAI. See the list of models here:
# https://platform.openai.com/docs/models
# Example: gpt-4o-mini
LLM_MODEL=

# The LLM you want to use from Ollama when running locally
#OLLAMA_MODEL=deepseek-r1:8b
OLLAMA_MODEL=

# The URL to use Ollama when running on anohter computer // pod
OLLMA_URL=http://localhost:11434/api/generate

# the Url os the site to crwal, best it to use the sitemap.xml
SITE_URL=

# Topic related with the actual site
TOPIC=

# Max concurrent tasks to run at a time
MAX_CONCURRENT_TASKS=
